FROM bardend123/hdfs-hadoop-spark-base:v2

ARG SPARK_WORKER_PORT
ARG SPARK_MASTER_PORT
ARG SPARK_MASTER_WEBUI_PORT
ARG SPARK_MASTER_HOST
ARG SPARK_HOME
ARG MASTER_HOST
ARG DIR_VOL_DATANODE

ENV SPARK_WORKER_PORT=${SPARK_WORKER_PORT}
ENV SPARK_MASTER_HOST=${SPARK_MASTER_HOST}
ENV SPARK_MASTER_PORT=${SPARK_MASTER_PORT}
ENV SPARK_HOME=${SPARK_HOME}
ENV SPARK_WORKER_LOG=${SPARK_HOME}/logs
ENV MASTER_HOST=${MASTER_HOST}
ENV DIR_VOL_DATANODE=${DIR_VOL_DATANODE}
ENV HDFS_CONF_NAMENODE_DIR=file://${DIR_VOL_DATANODE}

RUN mkdir -p "${DIR_VOL_DATANODE}"
VOLUME ["${DIR_VOL_DATANODE}"]

COPY run.sh /run.sh
RUN chmod +x /run.sh

# Puertos Spark Worker
EXPOSE ${SPARK_WORKER_PORT}
# Puertos HDFS DataNode (datos: 9866, IPC: 9867, HTTP: 9864)
#EXPOSE 9866 9867 9864

CMD ["/run.sh"]